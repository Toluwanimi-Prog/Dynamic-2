[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dynamic Group 2",
    "section": "",
    "text": "Preface\nHello and Welcome!\nThis book is dedicated to showcasing the work of Group 2, a dynamic team of dedicated students from the Visualization class at the prestigious Oral Roberts University, Oklahoma, under the guidance of Dr. V. Here, you’ll find weekly Quarto documents and exciting projects as they explore the world of data visualization.\nThe Members of the Group 2 are\n\nAbigail Tako\nCaleb Pena\nDerrick Baruga\nToluwanimi Olufawo\n\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "Introduction.html",
    "href": "Introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "2 Welcome to Group 2’s Book\nThis book is dedicated to showcasing the work of Group 2, a dynamic team of dedicated students from the Visualization class at the prestigious Oral Roberts University, Oklahoma, under the guidance of Dr. V. Here, you’ll find weekly Quarto documents and exciting projects as they explore the world of data visualization.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "Introduction.html#group-members",
    "href": "Introduction.html#group-members",
    "title": "1  Introduction",
    "section": "2.1 Group Members",
    "text": "2.1 Group Members\n\nAbigail Tako\nCaleb Pena\nDerrick Baruga\nToluwanimi Olufawo",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "Tako_Main.html",
    "href": "Tako_Main.html",
    "title": "2  Abigail Tako",
    "section": "",
    "text": "2.1 Wednesday",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abigail Tako</span>"
    ]
  },
  {
    "objectID": "Tako_Main.html#wednesday",
    "href": "Tako_Main.html#wednesday",
    "title": "2  Abigail Tako",
    "section": "",
    "text": "2.1.1 Week 1\n\n\n2.1.2 Week 2\nHistogram\nIn week 2, data sets that I am using is air quality data set. After cleaning the data set explained below, select all the data and insert the histogram chart to create the visualization of the data. The variables for the histogram chart is only the ozone. From the histogram, it shows the distribution of the ozone, most of the ozone are 1 to 25 ppm.\n\nclean data\nFirst, from the data, we are going to clean the data, by removing those that are have the value NA or not available.\n1. Select all the data, and search for the filter.\n2. Then, it will appear the drop down menu for each column, select the drop down menu on the first column which is Ozone\n3. Select NA. To remove it, select all from the row that has NA until the bottom and select delete rows 6-151.\n4. Select the drop down menu on column Ozone, select all and apply, it will give back the table, however there’s no NA anymore on the Ozone.\nLooking at the data, there still some NA on the column B for Solar.R. Repeat the way just like before. Next, to make it earlier to read the data, sort the day and month to be in order. Select the column for month, click the sort from smallest to largest, do the same for day.\nScatter plot\nUsing the air quality data sets, click on column A(ozone) and D (temperature) to show the correlation between both of them. After clicking on both column, I’m going to insert the scatter plot. The scatter plot shows a relationship between Ozone levels (y-axis) and Temperature (x-axis). The general trend indicates a positive correlation: as the temperature increases, the ozone level tends to increase as well.\n\nPivot Table & Chart\nTo make a pivot table and chart, first select all the data, and click insert. On the let corner, it will appear the pivot menu, press that and select the create own pivot table. I select and drag ozone, temperature, Solar. R, and Wind to the value, for the row I’ll put only the month. Then, I change the value field settings to average, this is to provide the average of ozone, temperature, Solar. R, and Wind monthly. After doing the pivot table, select that pivot table and insert the pivot chart to create the visualization.\n\nFrom the pivot table and chart above, it shows that ozone levels appear to increase with higher temperature and solar radiation but decrease with higher wind speeds.\nNext, I’m going to provide another pivot table, that shows the average of ozone, temperature, Solar. R, and Wind daily from day 1 to 31. To do that, select again the first table, the one that was cleaned, then again select the pivot table and choose the create own pivot table.\nI select and drag ozone, temperature, Solar. R, and Wind to the value, for the row I’ll put only the day. Then, I change the value field settings to average, this is to provide the average of ozone, temperature, Solar. R, and Wind per day.\nNow, I’m going to add the pivot chart from that new pivot table. I choose two charts, from those two I can create conclusion and better visualizations.\nFrom the chart presented below, the average daily of Temperature and Wind each have a positive correlation, however not with the average daily of Solar. R and the Ozone. Also, on day 15 it shows the lowest average of ozone and solar. r.\n\nThird, I’m going to make another pivot table that can show more detailed on each month per day.I’m going to choose to present the 5th month, so I’m going to press the drop down menu from the column “month” and select only the 5. Next, the table will only provide the information from month 5, day 1-31 and the sum of ozone, wind, temp, and solar.r.\n\nFrom the chart, we can see that, on day 30 from the 5th month, it shows the highest sum of ozone.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abigail Tako</span>"
    ]
  },
  {
    "objectID": "Tako_Main.html#friday---midterm-projects",
    "href": "Tako_Main.html#friday---midterm-projects",
    "title": "2  Abigail Tako",
    "section": "2.2 Friday - Midterm Projects",
    "text": "2.2 Friday - Midterm Projects\n\n2.2.1 Week 1\n\n\n2.2.2 Week 2\nWho collected the data\nThe source that I chose is National Transportation Library (NTL) Data. There are lots of data sets from NTL, which can be access through https://ntl.bts.gov/ntl. Data set that I chose is motor vehicle safety. This data set is collected by U.S. Department of Transportation, National Highway Traffic Safety Administration, National Center for Statistics and Analysis, and Fatality Analysis Reporting System (FARS) Database. I’m interested in this one, because it is critical to understand trends in road safety, which is a major public concern. The data that I collect is from this link https://www.bts.gov/content/motor-vehicle-safety-data.\nPurpose\nMonitoring the trends in motor vehicle safety in the U.S., including fatalities, injuries, and crashes. It serves to assess the effectiveness of safety regulations, technology advancements, and policy interventions over time. From the visualizations, it can improve the safety measures and highlight the effectiveness of road safety interventions over the years, making it highly valuable for assessing long-term changes in traffic-related fatalities and injuries.\nVariables\n\nFatalities - total number of deaths from motor vehicle crashes\nInjured persons - total number of people injured in motor vehicle accidents\nCrashes - total number of motor vehicle crashes\nVehicles miles traveled - total number of miles driven by vehicles",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abigail Tako</span>"
    ]
  },
  {
    "objectID": "Caleb_Main.html",
    "href": "Caleb_Main.html",
    "title": "3  Caleb Pena",
    "section": "",
    "text": "3.1 Wednesday",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Caleb Pena</span>"
    ]
  },
  {
    "objectID": "Caleb_Main.html#wednesday",
    "href": "Caleb_Main.html#wednesday",
    "title": "3  Caleb Pena",
    "section": "",
    "text": "3.1.1 Week 1\n\n\n3.1.2 Week 2\nWednesday, September 4, 2024\nI am using the airquality dataset, which is a collection of data collected from 153 observations based on 6 different variables. These variables include:\nOzone (Numeric) - Mean ozone in parts per billion from 1300 to 1500 hours at Roosevelt Island\nSolar R (Numeric) - Solar radiation in Langleys in the frequency band 4000–7700 Angstroms from 0800 to 1200 hours at Central Park\nWind (Numeric) - Average wind speed in miles per hour at 0700 and 1000 hours at LaGuardia Airport\nTemp (Numeric) - Maximum daily temperature in degrees Fahrenheit at La Guardia Airport\nMonth (Numeric) - Months from May to September\nDay (Numeric) - Days of the months ranging from 1 to 31\nI am using Excel to clean the data, which removes all the rows which have N/A values, and I did an exploration analysis.\nOzone vs Temperature Histogram\nThis histogram represents the amount of temperature values calculated within each border of values of ozone. For example, in the range of ozone level between 1 and 25, there were 49 temperature values recorded.\n\nOzone vs Temperature Scatter Plot\nThis scatter plot displays the correlation between the ozone levels and the temperature values recorded within these five months. As the ozone level increased, so did the temperature value, with one outlier.\n\nMy First PivotTable\nThis PivotTable displays the average values of each variable for each of the five months.\n\nMy Second PivotTable\nThis PivotTable displays the average temperature values for each day of each month.\n\n\n\n3.1.3 Week 3",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Caleb Pena</span>"
    ]
  },
  {
    "objectID": "Caleb_Main.html#friday---midterm-projects",
    "href": "Caleb_Main.html#friday---midterm-projects",
    "title": "3  Caleb Pena",
    "section": "3.2 Friday - Midterm Projects",
    "text": "3.2 Friday - Midterm Projects\n\n3.2.1 Week 1\n\n\n3.2.2 Week 2\nFriday, September 6, 2024\nUsing the same airquality datasets, I worked on creating PivotCharts from previous and new PivotTables comparing different values and variables.\nPivotChart1 - Average Variable Values by ‘Month’\nThis pivot table produced this chart. These are the average values of each variables for each of the five months. The PivotChart shows the comparison between each of the variables and how each one increases or decreases throughout the five months.\n\n\nPivotChart2 - Average Ozone Values by ‘Temp’\nThis pivot table produced this chart. This PivotChart displays the average ozone values for each temperature value that was recorded. As the temperature values increase, the average values for the ozone can be seen to also increase in a correlated way.\n\n\nPivotChart3 - Average Temp and Ozone Values by ‘Wind’\nThis pivot table produced this chart. This PivotChart displays the average values of both temperature and ozone for each wind value recorded. From the chart, it is evident that as the wind values increase, the average values for temperature seem to slightly decrease and the average values for the ozone levels seem to greatly decrease.\n\n\nNewport Oregon Oceanographic Temperature Dataset\nStarting off in the year 1996, a group of NOAA Fisheries and Oregon State University Scientists sampled the Newport Hydrographic Line fortnightly to understand changing ocean conditions. The various variable data was collected from a station located 5 miles off the coast of Newport, Oregon. The scientists sampled and collected data regarding seven different variables:\nDay (Numerical) - The specific day of the month in which the data was sampled.\nMonth (Numerical) - The specific month of the year in which the data was sampled.\nYear (Numerical) - The specific year in which the data was sampled.\nTemperature (Numerical) - Oceanographic, temperature data collected from a 50 m water depth.\nOxygen (Numerical) - Oceanographic, oxygen data collected from a 50 m water depth.\nNorthern Copepod Biomass (Numerical) - Copepod community data collected from from vertical net samples on the northern area\nSouthern Copepod Biomass (Numerical) - Copepod community data collected from from vertical net samples on the southern area\nVisualizations\nThe descriptive statistics of all the water temperatures sampled throughout the 28 years. The average temperature of all collective 28 years is 8.75 ºC. The lowest temperature recorded of all 28 years is 6.92 ºC and the highest temperature recorded from all 28 years is 14.65 ºC.\n\nThe peak temperatures of the water during the winter have a higher average than the peak temperatures of the water during the summer.\n\nThrough the dot plot, the average of the temperatures is 8.75 ºC as most of the dot population is visible there.\n\nThe average temperatures of all collective 28 years gathered within each month. During the summer months, the averages are lower. During the winter months, the averages are higher.\n ### Week 3",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Caleb Pena</span>"
    ]
  },
  {
    "objectID": "Baruga_Main.html",
    "href": "Baruga_Main.html",
    "title": "4  Derrick Baruga",
    "section": "",
    "text": "4.1 Wednesday",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Derrick Baruga</span>"
    ]
  },
  {
    "objectID": "Baruga_Main.html#wednesday",
    "href": "Baruga_Main.html#wednesday",
    "title": "4  Derrick Baruga",
    "section": "",
    "text": "4.1.1 Week 1\n\n\n4.1.2 Week 2\nI am using the air-quality dataset, which contains air quality measurements collected over several months, specifically from May to September. The dataset includes the following variables: Ozone, Solar.R (solar radiation), Wind (wind speed in miles per hour), Temp (temperature in degrees Fahrenheit), Month (ranging from 5 for May to 9 for September), and Day (ranging from 1 to 31).\nCleaning The Data\nI used Excel to clean the data by removing all rows with NA values and performed an exploratory analysis to identify patterns, trends, and potential relationships between these variables over the specified months and days.\nOzone Histogram\n\nThe Ozone histogram has its highest values on the left and then curbs off to the right, it indicates a right-skewed distribution.\nThis means:\n\nMost ozone values are low, with a few much higher values creating a long tail on the right.\nThe skewness could result from natural variability, pollution events, or weather conditions affecting ozone levels.\n\nScatter Plot Ozone vs Temperature\n\n\nA scatter plot of ozone (x-axis) vs. temperature (y-axis) with a slight positive correlation means that higher ozone levels tend to be associated with higher temperatures. However, the relationship is weak, suggesting other factors (like wind, humidity, or pollution) also affect ozone levels and temperature.\n\nPivot Table Average Ozones Per Day & Month (Redacted)\n\n\nThe pivot table presents daily sums for multiple variables (Temperature, Wind, Solar Radiation, and Ozone) over several months (May to September). The days with the highest ozone averages are Day 25 in May (with an Ozone value of 5-65) and July (with an Ozone value of 7-74), with other notable days being Day 29 and Day 30 in May. The months with the highest ozone levels are May, which shows several days with high averages, and July, particularly on Days 25 and 29.\n\nPivot Chart Average Ozones Per Day & Month\n\nPivot Table of Variation in Solar Radiation and Temperature\n\nThe pivot chart provide a visual representation of how these variables change over time. The histogram shows day-to-day variations in ozone levels, with the highest concentrations occurring in the summer months. Notably, there is a pronounced peak around July 25th, indicating exceptionally high ozone levels on that day. May and July both have elevated levels, with smaller peaks around May 29th and 30th, but July 25th stands out as the most significant. Overall, the chart confirms that ozone levels are highest in July, particularly around the 25th.\n\n\n\nThe pivot table shows daily sums for Solar Radiation and Temperature over a month. There is noticeable daily variation, with high values on days like 18, 19, and 29, indicating intense sunlight and warmer temperatures, and lower values on days like 23 and 27, reflecting cooler conditions. The grand totals summarize the entire month, with 20,513 for Solar Radiation and 8,635 for Temperature. Overall, the table captures daily fluctuations in weather conditions.\n\n** Pivot Chart of Pivot Chart of Variation in Solar Radiation and Temperature**\n\n\nThe bar chart shows daily sums of Solar Radiation (blue) and Temperature (orange) over 31 days. High Solar Radiation is notable on days like 9, 13, 16, 18, 19, and 29, with values exceeding 1,000. Temperature values are generally lower, mostly below 400, with higher values on days like 9 and 18. There are significant day-to-day variations, with some days showing high Solar Radiation but lower temperatures (e.g., Day 13). The chart captures daily fluctuations and highlights days with extreme values.\n\nPivot Table\n\n\nThe pivot table displays the average temperature (Average of Temp) and ozone levels (Average of Ozone) for days labeled 5 to 9, showing average temperatures ranging from 66.46 to 83.88, with the highest temperatures recorded on days 7 and 8. Ozone levels vary significantly, from a low of 24.13 on Day 5 to a high of 60.00 on Day 8. Overall, the average temperature for the period is 77.79, and the average ozone level is 42.10, reflecting moderate temperatures with variable ozone levels across these days and highlighting daily fluctuations in both metrics.\n\nPivot Chart\n\n\nThe bar chart illustrates the average temperature (in blue) and average ozone levels (in orange) for days 5 to 9, showing that temperatures remain relatively high throughout, ranging from around 66 on Day 5 to approximately 84 on Days 7 and 8. Ozone levels start low on Day 5 (around 24), rise significantly by Days 7 and 8 (around 59-60), and then decrease slightly on Day 9 (around 31). The chart suggests a potential correlation between higher temperatures and elevated ozone levels, as Days 7 and 8, which have the highest temperatures, also show the highest average ozone levels, indicating noticeable variability over the period.\n\n\n\n4.1.3 Week 3",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Derrick Baruga</span>"
    ]
  },
  {
    "objectID": "Baruga_Main.html#friday---midterm-projects",
    "href": "Baruga_Main.html#friday---midterm-projects",
    "title": "4  Derrick Baruga",
    "section": "4.2 Friday - Midterm Projects",
    "text": "4.2 Friday - Midterm Projects\n\n4.2.1 Week 1\n\n\n4.2.2 Week 2\ntitle: “Midterm_Project_Baruga” subtitle: “Data.gov: Warehouse and Retail Sales” format: html —\nContext of the Dataset\n\nTitle: Warehouse and Retail Sales\nLink: Download the CSV dataset\n\nThe Warehouse and Retail Sales dataset provides a comprehensive view of sales activities in Montgomery County, Maryland, by capturing data from various warehouse and retail operations. This dataset was collected through a combination of direct reporting from businesses, automated sales tracking systems, and regional sales surveys. The data encompasses a range of sales metrics, including volume and product categories, to offer insights into business performance across different types of establishments.\nThe dataset includes the following variables:\n\nRow Labels: Categories or identifiers used to organize and classify the sales data.\nBEER: Sales volume for beer products.\nDUNNAGE: Sales volume for dunnage products, which are materials used to protect goods during transportation.\nKEGS: Sales volume for kegs, typically used for storing and transporting beverages.\nLIQUOR: Sales volume for liquor products.\nNON-ALCOHOL: Sales volume for non-alcoholic beverages.\nREF: Sales volume for refrigeration supplies or products.\nSTR_SUPPLIES: Sales volume for store supplies, which may include various retail essentials.\nWINE: Sales volume for wine products.\nGrand Total: The total sales volume across all categories combined.\n\n** Data Cleaning and Preparation**\n\nImport the Data: I downloaded and loaded the CSV file into Excel.\nCheck for Missing Values: My preferred method for handling NAs is by highlighting them and deselecting them using the filter tool for each column as I feel most thorough by doing that. Using the following steps “Select the entire dataset, go to Home &gt; Conditional Formatting &gt; Highlight Cells Rules &gt; Blanks to highlight all blank cells.”\nData Formatting: Formated any columns that need specific data types (such as dates as date format, numbers as currency or percentage).\n\n\nSpecifically I used the =TEXTJOIN(“-”, TRUE, A2, B2) function to join column one (YYYY) and column two (MM) into a new column called TIME\n\n\nVisualization\nPivot Tables YT link: https://www.youtube.com/watch?v=qu-AK0Hv0b4\n\nPivot tables are a powerful and user friendly (drag and drop) summary statistic/visualisation tool that I used to get an intial feel of my data.\n\nHere are the findings:\nWarehouse Sales/Expenses of Beverages Over Time (2017 - 2020)\n\n\nOverall Sales: BEER has the highest sales, followed by WINE, while DUNNAGE, REF, and STR_SUPPLIES have negative or minimal sales, which makes sense as refers to materials used to protect goods during shipping and handling, such as packing materials or cushioning, and as such is an expense to the business leading to its negative output on revenue.\nMonthly Trends: BEER sales vary significantly, with large peaks and drops. WINE sales are more stable but still show some fluctuation. KEGS and LIQUOR show positive but lower sales.\n\nHistogram of Warehouse Sales/Expenses of Beverages Over Time\n\n\nHere is a histogram representation of the aforementioned summary pivot tables. There appears to be a disporportionate amount of BEER bought for warehouses. But that could be due to the fact that beers are sold in packs and so single unit quantity has skyrocketed in order to make a “12 pack” that will later count as one unit sold at retail.\n\nRetail Sales of Beverages Over Time (2017 - 2020)\n\n\nProduct Types: Includes Beer, Liquor, Wine, Non-Alcoholic beverages, and others, with substantial sales figures for Beer, Liquor, and Wine.\nSales Trends: Liquor leads with $802,691.43 in total sales, followed by Wine ($746,498.59) and Beer ($574,220.53). Recent months show higher sales for Beer and Wine.\nLow Sales Categories: Items like Dunnage and Kegs have negligible or zero sales.\nOverall Total: Total sales across all products amount to $2,160,899.37, highlighting overall retail activity.\n\nHistogram of Retail Sales of Beverages Over Time\n\n\nOnce we come to the retail side of things we see that WINE and LIQUOR are clear best sellers. It is shown hower that LIQUOR has begun to overtake WINE in retail sales.\n\nSummary\nFrom the “Warehouse and Retail Sales” dataset, I found that Beer leads in warehouse sales, with notable fluctuations due to bulk packaging, while Wine and Liquor have more stable sales. Retail sales show Liquor as the top seller, recently surpassing Wine, with Beer also performing strongly but declining. The histograms illustrate high Beer volume in warehouses and a shift in retail dominance from Wine to Liquor. Next, I will analyze seasonal trends, create advanced visualizations for deeper insights, and finalize the report with comprehensive findings and recommendations. ### Week 2 ### Week 3\n\n\n4.2.3 Week 3",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Derrick Baruga</span>"
    ]
  },
  {
    "objectID": "Toluwanimi_Main.html",
    "href": "Toluwanimi_Main.html",
    "title": "5  Toluwanimi Olufawo",
    "section": "",
    "text": "5.1 Monday",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Toluwanimi Olufawo</span>"
    ]
  },
  {
    "objectID": "Toluwanimi_Main.html#monday",
    "href": "Toluwanimi_Main.html#monday",
    "title": "5  Toluwanimi Olufawo",
    "section": "",
    "text": "5.1.1 Week 1\n\n\n5.1.2 Week 2\n\n\n5.1.3 Week 3\nMonday Tableau Tutorial\nIn Monday’s class, we learned how to use Tableau Public. We began by downloading and installing the software or using the web version. We then imported the dataset (airquality_datasets.csv) and cleaned the data by checking for missing values and renaming columns.\nImporting the Dataset: After opening Tableau Public, I clicked on “Connect to Data,” selected “Text File,” and navigated to the dataset (airquality_datasets.csv). Then I clicked “Open” or dragged and dropped the file.\nVisualization:\nBar Chart for Average Ozone Levels by Month: We dragged ‘Month’ to Rows and ‘Ozone’ to Columns, then aggregated Ozone as an average. If Tableau didn’t automatically create a bar chart, we changed the Marks type to Bar and renamed the sheet tab. Line Chart for Ozone Levels Over Days: In a new worksheet, we dragged ‘Day’ to Columns and ‘Ozone’ to Rows, creating a line chart, and explored properties like color. Scatter Plot for Temperature vs. Ozone: We created a new worksheet, dragged ‘Temp’ to Columns and ‘Ozone’ to Rows. If Tableau defaulted to a Measure, we changed each pill to Dimension. If not showing a scatter plot, we selected Shape in the Marks tab. Map Visualization: Since our dataset didn’t include geographical data like Latitude and Longitude, we skipped this step.\nCreating a Pivot Table: In a new worksheet, we dragged ‘Month’ to Rows, ‘Day’ to Columns, ‘Ozone’ to Color, and ‘Ozone’ to Size. We observed the resulting pivot table and experimented with the added dimensions.\nBuilding a Dashboard: We clicked on the New Dashboard button, dragged and dropped our created sheets onto the dashboard area, arranged them cohesively, and added interactivity using filters and actions. We reviewed the ozone vs. day line plot and considered improvements or fixes.\n\nConclusion\nIn this class , we gained hands-on experience with Tableau Public, from importing and cleaning data to creating a variety of visualizations, including bar charts, line charts, scatter plots, and pivot tables. We also learned how to build interactive dashboards to present our findings in a cohesive way. These skills will be useful for analyzing and visualizing complex datasets, making it easier to draw insights and communicate results effectively.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Toluwanimi Olufawo</span>"
    ]
  },
  {
    "objectID": "Toluwanimi_Main.html#wednesday",
    "href": "Toluwanimi_Main.html#wednesday",
    "title": "5  Toluwanimi Olufawo",
    "section": "5.2 Wednesday",
    "text": "5.2 Wednesday\n\n5.2.1 Week 1\n\n\n5.2.2 Week 2\nSeptember 4 2024\nDuring class today, we learnt about how to create pivot tables using excel and how best to properly present our data to convey the information we found accurately.\nData Description/Selection By using the air-quality dataset, which contains air quality measurements collected from May to September 1973 in New York united states of America. This dataset includes:\n\nOzone\nSolar.R (solar radiation)\nWind (wind speed in mph)\nTemp (temperature in Fahrenheit)\nMonth (May to September)\nDay (1 to 31)\n\nSource\n1.Open the Dataset: The data were sourced from the New York State Department of Conservation (for ozone data) and the National Weather Service (for meteorological data). I obtained an updated version of the airquality.csv file\n2.Identify and Address Missing Values:\nData Cleaning Process: Fill or Remove Missing Values:\nI cleaned the dataset using Excel by removing rows with missing values (NA) and performed exploratory analysis to reveal patterns and trends in ozone levels and other variables.\nVariables to be evaluated In this dataset,i will be using the Temperature and ozone\nStep 2:Creating a PivotTable\nI selected the entire dataset using Ctrl+A, then went to the Insert tab and clicked on PivotTable. I chose to place the PivotTable in a New Worksheet and clicked OK. To set it up, I dragged Month to the Rows area, Day to the Columns area, and Ozone, Solar.R, Wind, and Temp to the Values area. I made sure each value displayed as an Average by clicking the dropdown next to each field in the Values area, selecting Value Field Settings, and choosing Average. Finally, I customized the PivotTable’s design using the Design tab and adjusted the number formatting by right-clicking on the data cells.\n\nStep 3:Creating Visualizations Insert a PivotChart and Customize the Chart: I clicked inside the PivotTable, then went to the Insert tab and selected PivotChart. I chose the chart type that best suited my data, like a Line Chart for trends or a Bar Chart for comparisons, and clicked OK. To customize the chart, I used the Chart Tools to adjust the design, layout, and format, and added essential elements such as titles, axis labels, and legends to enhance readability.\n\nStep 4: Experiment with Different Configurations\nI clicked inside the PivotTable, then went to the Insert tab and selected PivotChart. I chose the chart type that best suited my data, like a Line Chart for trends or a Bar Chart for comparisons, and clicked OK. To customize the chart, I used the Chart Tools to adjust the design, layout, and format, and added essential elements such as titles, axis labels, and legends to enhance readability.\n\nOzone Histogram\n\nThe Ozone distribution shows a right-skewed pattern, indicating that most values are low, with a few high outliers. This could reflect variations in weather or pollution.\nScatter Plot: Ozone vs Temperature\n\nThere is a weak positive correlation between ozone and temperature, suggesting that higher temperatures tend to coincide with higher ozone levels, though other factors like wind or pollution likely contribute.\nAverage Ozone Per Day & Month\n\nThe highest ozone averages occur on May 25th and July 25th, with notable peaks also on May 29th and July 30th. July generally exhibits higher ozone levels, especially around the end of the month.\nSolar Radiation and Temperature Variations\n\nThe chart reveals daily variations in solar radiation and temperature, peaking around days 18, 19, and 29. Both solar radiation and temperature are higher on these days, pointing to intense sunlight and warmth during these periods.\nConclusion\nAfter setting up the PivotTable by selecting the dataset and placing it in a new worksheet, I configured it with Month in the Rows, Day in the Columns, and used Ozone, Solar.R, Wind, and Temp, showing their averages in the Values area. I tweaked the design and number formatting to make it look cleaner. Then, I inserted a PivotChart based on the table, chose the best chart type for my data, and added titles and labels for clarity. To wrap it up, I explored different configurations by switching variables around, like moving Temp to the Axis and Average Ozone to the Values, to see which setup gave the best visual insight into my data. This process helped me organize and present the information in a clear, visually appealing way.\n\n\n5.2.3 Week 3\nWednesday Tableau Tutorial\nIntroduction The Diamonds dataset is widely used for statistical analysis and data visualization, providing information about various attributes of over 50,000 diamonds, such as their carat weight, cut quality, clarity, and price. The aim of this assignment is to clean the dataset, check for any missing values, and create meaningful visualizations using Tableau\nImporting the Dataset:\nSteps to Import the Dataset:\nOpened Tableau and go to File &gt; Open to upload the “Diamonds Dataset (ggplot2).csv.”\nNavigate to File &gt; Open and select the diamonds_ggplot2.csv file to import the data.\nCleaning the Dataset The data set does not have any missing values, but i ensured all the data types are correct. Ensure Data Types Are Correct: Carat: Number (decimal) Cut: String Color: String Clarity: String Depth, Table, Price, X, Y, Z: Numbers\nCreating Visualizations\n1. Bar Chart: Average Price by Cut To explore how diamond prices vary based on their cut quality, I created a bar chart showing the average price for each cut category This chart will show how the average price varies based on the cut quality of the diamonds.\nSteps I Followed: 1.I dragged Cut to the Rows shelf. 2.Then, I dragged Price to the Columns shelf. 3.To see the average price instead of the sum, I right-clicked on Price, selected Measure, and changed it to Average.\nThis gave me a clear view of how diamonds with different cut qualities (Ideal, Premium, etc.) are priced on average.\n\n2.Line Chart: Price Over Carat Next, I wanted to see how the price changes as the carat size increases, so I built a line chart for this.\nSteps I Followed: 1.I dragged Carat to the Columns shelf. 2.Then, I dragged Price to the Rows shelf. 3.To adjust the chart type to a line, I switched the chart type to Line from the Marks card.\nThis line chart helped me visualize how diamonds with larger carat weights tend to have higher prices, showing a clear upward trend.\n\n3. Scatter Plot: Price vs. Carat To get a more detailed look at the relationship between carat weight and price, I created a scatter plot. This allowed me to see the individual diamond data points more clearly.\nSteps I Followed: 1.I dragged Carat to the Columns shelf. 2.Then, I dragged Price to the Rows shelf.\nThis generated a scatter plot that gave me a more granular view of how price is influenced by carat size. The scatter plot revealed the spread of data, showing how prices vary widely for diamonds of similar carat weights.\n\nCreating a Pivot Table After visualizing the data, I wanted to summarize the diamond prices across different cut and color combinations, so I built a pivot table.\nSteps I Followed: 1.I dragged Cut to the Rows shelf. 2.Then, I dragged Color to the Columns shelf. 3.Finally, I dragged Price to Text (or Label) to display the prices. 4.I right-clicked on Price and summarized it by Average to show the average price for each combination of cut and color This pivot table allowed me to easily compare prices across various cut and color categories.\n\nConclusion Through this assignment, I was able to successfully import, clean, and analyze the Diamonds dataset. By ensuring the data was properly cleaned and validated, I created several visualizations, including a bar chart, line chart, and scatter plot. Each provided valuable insights into how different attributes like cut and carat size influence diamond prices. Additionally, I summarized the data using a pivot table, which made it easy to see price variations across different cut and color combinations. Tableau’s flexibility allowed me to explore the dataset interactively, giving me a deeper understanding of the relationships within the data",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Toluwanimi Olufawo</span>"
    ]
  },
  {
    "objectID": "Toluwanimi_Main.html#friday--midterm-projects",
    "href": "Toluwanimi_Main.html#friday--midterm-projects",
    "title": "5  Toluwanimi Olufawo",
    "section": "5.3 Friday- Midterm Projects",
    "text": "5.3 Friday- Midterm Projects\n\n5.3.1 Week 1\n\n\n5.3.2 Week 2\n\n\n5.3.3 Week 3",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Toluwanimi Olufawo</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "6  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary</span>"
    ]
  }
]