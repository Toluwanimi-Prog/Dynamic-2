setwd("C:/Users/toluf/OneDrive/Desktop/Dynamic_Group_2")
?iris
quarto install tinytex
quarto install tinytex
## Jupyter Notebook
## Week 4
- [Toluwanimi's Notebook](Tut2_Python_Olufawo_092024.ipynb): This notebook contains the data cleaning and exploration tasks.
# R to load a CSV file
dataset <- read.csv("C:/Users/toluf/OneDrive/Desktop/Visualization_Midterm_Report_Olufawo/Week3_Geoheritage_Dataset_Sites_Cleaned.csv")
head(dataset)  # Shows the first 6 rows by default
str(dataset)
summary(dataset)
colSums(is.na(dataset))  # Shows the count of missing values per column
colnames(dataset)
load("C:/Users/toluf/OneDrive/Desktop/Dynamic 2/.RData")
cd "C:\Users\toluf\Downloads\week7_baruga_r\Archive 2"
cd "C:\Users\toluf\OneDrive\Desktop\Dynamic 2"
# Load necessary libraries
library(readxl)  # To read Excel files
library(dplyr)   # For data manipulation
library(ggplot2) # For visualization
library(readxl)  # To read Excel files
library(dplyr)   # For data manipulation
library(ggplot2) # For visualization
# Task 1: Load the dataset
file_path <-  "C:/Users/toluf/OneDrive/Desktop/Dynamic 2/Archive 2/~$table_03_29_061324.xlsx"
# Explore the structure of the dataset
str(dataset)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
install.packages("reticulate")
library(reticulate)
# Load libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(tidyr)  # New: for better reshaping of data
library(janitor) # New: for quick data cleaning
install janitor
installed.packages(janitor)
install.packages("janitor")
# Load libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(tidyr)  # New: for better reshaping of data
library(janitor) # New: for quick data cleaning
# Task 1: Load the dataset
file_path <- "C:/Users/toluf/OneDrive/Desktop/Visualization/Group Project/Group_Projectdata.xlsx"
dataset <- read_excel(file_path, sheet = "3-1") %>%
clean_names()  # Automatically cleans and standardizes column names
# Explore the structure and check for basic issues
glimpse(dataset)  # New: Offers a quick summary overview of data
# Identifying missing values in a more detailed way
missing_vals <- dataset %>%
summarise(across(everything(), ~ sum(is.na(.)))) %>%
pivot_longer(everything(), names_to = "column", values_to = "missing_count")
print(missing_vals)  # Check where missing data exists
# Visualize missing data using ggplot
ggplot(missing_vals, aes(x = column, y = missing_count)) +
geom_bar(stat = "identity") +
theme_minimal() +
labs(title = "Missing Data Overview", x = "Columns", y = "Count of Missing Values") +
coord_flip()
# Task 2: Cleaning the data
# - We'll focus on removing extreme outliers instead of just using boxplots
# - Use custom logic to handle missing data, possibly median or interpolation
# Remove duplicated rows and filter out non-numeric columns
dataset_clean <- dataset %>%
distinct() %>%
filter(!is.na(description))  # Make sure description column has valid values
# Task 2: Cleaning the data
**We'll focus on removing extreme outliers instead of just using boxplots**
# Load libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(tidyr)  # New: for better reshaping of data
library(janitor) # New: for quick data cleaning
# Task 1: Load the dataset
file_path <- "C:/Users/toluf/OneDrive/Desktop/Visualization/Group Project/Group_Projectdata.xlsx"
dataset <- read_excel(file_path, sheet = "3-1") %>%
clean_names()  # Automatically cleans and standardizes column names
# Explore the structure and check for basic issues
glimpse(dataset)  # New: Offers a quick summary overview of data
# Identifying missing values in a more detailed way
missing_vals <- dataset %>%
summarise(across(everything(), ~ sum(is.na(.)))) %>%
pivot_longer(everything(), names_to = "column", values_to = "missing_count")
print(missing_vals)  # Check where missing data exists
# Visualize missing data using ggplot
ggplot(missing_vals, aes(x = column, y = missing_count)) +
geom_bar(stat = "identity") +
theme_minimal() +
labs(title = "Missing Data Overview", x = "Columns", y = "Count of Missing Values") +
coord_flip()
# Remove duplicated rows and filter out non-numeric columns
dataset_clean <- dataset %>%
distinct() %>%
filter(!is.na(description))  # Make sure description column has valid values
dataset_clean <- dataset %>
# Visualize missing data using ggplot
ggplot(missing_vals, aes(x = column, y = missing_count)) +
geom_bar(stat = "identity") +
theme_minimal() +
labs(title = "Missing Data Overview", x = "Columns", y = "Count of Missing Values") +
coord_flip()
# Remove duplicated rows and filter out non-numeric columns
dataset_clean <- dataset %>%
distinct() %>%
filter(!is.na(description))  # Make sure description column has valid values
colnames(dataset)
file_path <- "C:/Users/toluf/OneDrive/Desktop/Visualization/Group Project/Group_Projectdata.xlsx"
dataset <- read_excel(file_path, sheet = "3-1") %>%
clean_names()  # Automatically cleans and standardizes column names
library(readxl)
library(dplyr)
library(ggplot2)
library(tidyr)  # New: for better reshaping of data
library(janitor) # New: for quick data cleaning
file_path <- "C:/Users/toluf/OneDrive/Desktop/Visualization/Group Project/Group_Projectdata.xlsx"
dataset <- read_excel(file_path, sheet = "3-1") %>%
clean_names()  # Automatically cleans and standardizes column names
glimpse(dataset)  # New: Offers a quick summary overview of data
missing_vals <- dataset %>%
summarise(across(everything(), ~ sum(is.na(.)))) %>%
pivot_longer(everything(), names_to = "column", values_to = "missing_count")
print(missing_vals)  # Check where missing data exists
ggplot(missing_vals, aes(x = column, y = missing_count)) +
geom_bar(stat = "identity") +
theme_minimal() +
labs(title = "Missing Data Overview", x = "Columns", y = "Count of Missing Values") +
coord_flip()
colnames(dataset)
dataset_clean <- dataset %>%
distinct() %>%
filter(!is.na(description))  # Make sure description column has valid values
View(dataset)
colnames(dataset)
dataset_clean <- dataset %>%
distinct() %>%
filter(!is.na(sector_description))  # Replace 'description' with the actual column name
dataset_clean <- dataset_clean %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), zoo::na.approx(.), .)))  # Linear interpolation
colnames(dataset)
str(dataset)
colnames(dataset)
str(dataset)
# Identify missing values
sum(is.na(dataset))
# Remove rows with missing values
dataset <- na.omit(dataset)
file_path <- "C:/Users/toluf/OneDrive/Desktop/Visualization/Group Project/Group_Projectdata.xlsx"
dataset <- read_excel(file_path, sheet = "3-1") %>%
clean_names()  # Automatically cleans and standardizes column names
glimpse(dataset)  # New: Offers a quick summary overview of data
library(readxl)
data_xlsx <- read_excel("C:/Users/toluf/OneDrive/Desktop/Dynamic 2/cp_Finalmain/finalpro.xlsx", sheet = "Sheet2")
library(esquisse)
esquisse::esquisser(data_xlsx)
library(readxl)
data_xlsx <- read_excel("C:/Users/toluf/OneDrive/Desktop/Dynamic 2/cp_Finalmain/finalpro.xlsx", sheet = "Sheet2")
library(esquisse)
library(ggplot2)
ggplot(data_xlsx) +
aes(x = `TOTAL U.S. GDP`, y = `Air transportation...4`) +
geom_point(size = 2.25, colour = "#112446") +
labs(
y = "Air Transportation GDP",
title = "Air Transportation GDP on Total U.S. GDP"
) +
theme_bw()
